# ruff: noqa: E501
from __future__ import annotations

import io
import json
import logging
import re
import unicodedata
from collections.abc import Awaitable, Callable
from datetime import datetime
from typing import Any

logger = logging.getLogger(__name__)


class ResponseFormatter:
    """Handles message formatting and replies to Telegram users."""

    def __init__(
        self,
        safe_reply_func: Callable[[Any, str], Awaitable[None]] | None = None,
        reply_json_func: Callable[[Any, dict], Awaitable[None]] | None = None,
    ) -> None:
        # Optional callbacks allow the TelegramBot compatibility layer to
        # intercept replies during unit tests without duplicating formatter
        # logic. The callbacks are expected to be awaitable and accept the
        # same arguments as ``safe_reply`` / ``reply_json`` respectively.
        self._safe_reply_func = safe_reply_func
        self._reply_json_func = reply_json_func

    async def send_help(self, message: Any) -> None:
        """Send help message to user."""
        help_text = (
            "Bite-Size Reader\n\n"
            "Commands:\n"
            "- /help â€” show this help.\n"
            "- /summarize <URL> â€” summarize a URL.\n"
            "- /summarize_all <URLs> â€” summarize multiple URLs from one message.\n\n"
            "Usage:\n"
            "- You can simply send a URL (or several URLs) or forward a channel post â€” commands are optional.\n"
            "- You can also send /summarize and then a URL in the next message.\n"
            "- Multiple links in one message are supported; I can confirm or use /summarize_all to process immediately.\n\n"
            "Features:\n"
            "- Enhanced structured JSON output with schema validation\n"
            "- Intelligent model fallbacks for better reliability\n"
            "- Automatic content optimization based on model capabilities\n"
            "- /dbinfo â€” quick database health snapshot"
        )
        await self.safe_reply(message, help_text)

    async def send_welcome(self, message: Any) -> None:
        """Send welcome message to user."""
        welcome = (
            "Welcome to Bite-Size Reader!\n\n"
            "What I do:\n"
            "- Summarize articles from URLs using Firecrawl + OpenRouter.\n"
            "- Summarize forwarded channel posts.\n"
            "- Generate structured JSON summaries with enhanced reliability.\n\n"
            "How to use:\n"
            "- Send a URL directly, or use /summarize <URL>.\n"
            "- You can also send /summarize and then the URL in the next message.\n"
            "- For forwarded posts, use /summarize_forward and then forward a channel post.\n"
            '- Multiple links in one message are supported: I will ask "Process N links?" or use /summarize_all to process immediately.\n'
            "- /dbinfo shares a quick snapshot of the internal database so you can monitor storage.\n\n"
            "Notes:\n"
            "- I reply with a strict JSON object using advanced schema validation.\n"
            "- Intelligent model selection and fallbacks ensure high success rates.\n"
            "- Errors include an Error ID you can reference in logs."
        )
        await self.safe_reply(message, welcome)

    async def send_db_overview(self, message: Any, overview: dict[str, object]) -> None:
        """Send an overview of the database state."""
        lines = ["ğŸ“š Database Overview"]

        path = overview.get("path")
        if isinstance(path, str) and path:
            lines.append(f"Path: `{path}`")

        size_bytes = overview.get("db_size_bytes")
        if isinstance(size_bytes, int) and size_bytes >= 0:
            pretty_size = self._format_bytes(size_bytes)
            lines.append(f"Size: {pretty_size} ({size_bytes:,} bytes)")

        table_counts = overview.get("tables")
        if isinstance(table_counts, dict) and table_counts:
            lines.append("")
            lines.append("Tables:")
            for name in sorted(table_counts):
                lines.append(f"- {name}: {table_counts[name]}")

        total_requests = overview.get("total_requests")
        total_summaries = overview.get("total_summaries")
        totals: list[str] = []
        if isinstance(total_requests, int):
            totals.append(f"Requests: {total_requests}")
        if isinstance(total_summaries, int):
            totals.append(f"Summaries: {total_summaries}")
        if totals:
            lines.append("")
            lines.append("Totals: " + ", ".join(totals))

        statuses = overview.get("requests_by_status")
        if isinstance(statuses, dict) and statuses:
            lines.append("")
            lines.append("Requests by status:")
            for status in sorted(statuses):
                label = status or "unknown"
                lines.append(f"- {label}: {statuses[status]}")

        last_request = overview.get("last_request_at")
        last_summary = overview.get("last_summary_at")
        last_audit = overview.get("last_audit_at")
        timeline_parts: list[str] = []
        if isinstance(last_request, str) and last_request:
            timeline_parts.append(f"Last request: {last_request}")
        if isinstance(last_summary, str) and last_summary:
            timeline_parts.append(f"Last summary: {last_summary}")
        if isinstance(last_audit, str) and last_audit:
            timeline_parts.append(f"Last audit log: {last_audit}")
        if timeline_parts:
            lines.append("")
            lines.extend(timeline_parts)

        await self.safe_reply(message, "\n".join(lines))

    async def send_enhanced_summary_response(
        self, message: Any, summary_shaped: dict[str, Any], llm: Any, chunks: int | None = None
    ) -> None:
        """Send enhanced summary where each top-level JSON field is a separate message,
        then attach the full JSON as a .json document with a descriptive filename."""
        try:
            # Optional short header
            try:
                method = f"Chunked ({chunks} parts)" if chunks else "Single-pass"
                model_name = getattr(llm, "model", None)
                header = (
                    f"ğŸ‰ Summary Ready\nğŸ§  Model: {model_name or 'unknown'}\nğŸ”§ Method: {method}"
                )
                await self.safe_reply(message, header)
            except Exception:
                pass

            # Combined first message: TL;DR, Tags, Entities, Reading Time, Key Stats, Readability, SEO
            combined_lines: list[str] = []

            tl_dr = str(summary_shaped.get("summary_250", "")).strip()
            if tl_dr:
                tl_dr_clean = self._sanitize_summary_text(tl_dr)
                combined_lines.extend(["ğŸ“‹ TL;DR:", tl_dr_clean, ""])

            tags = [
                str(t).strip() for t in (summary_shaped.get("topic_tags") or []) if str(t).strip()
            ]
            if tags:
                combined_lines.append("ğŸ·ï¸ Tags: " + " ".join(tags))
                combined_lines.append("")

            entities = summary_shaped.get("entities") or {}
            if isinstance(entities, dict):
                people = [str(x).strip() for x in (entities.get("people") or []) if str(x).strip()]
                orgs = [
                    str(x).strip() for x in (entities.get("organizations") or []) if str(x).strip()
                ]
                locs = [str(x).strip() for x in (entities.get("locations") or []) if str(x).strip()]
                ent_parts: list[str] = []
                if people:
                    ent_parts.append("ğŸ‘¤ " + ", ".join(people[:10]))
                if orgs:
                    ent_parts.append("ğŸ¢ " + ", ".join(orgs[:10]))
                if locs:
                    ent_parts.append("ğŸŒ " + ", ".join(locs[:10]))
                if ent_parts:
                    combined_lines.append("ğŸ§­ Entities: " + " | ".join(ent_parts))
                    combined_lines.append("")

            reading_time = summary_shaped.get("estimated_reading_time_min")
            if reading_time:
                combined_lines.append(f"â±ï¸ Reading time: ~{reading_time} min")
                combined_lines.append("")

            key_stats = summary_shaped.get("key_stats") or []
            if isinstance(key_stats, list) and key_stats:
                ks_lines: list[str] = ["ğŸ“ˆ Key Stats:"]
                for ks in key_stats[:10]:
                    if isinstance(ks, dict):
                        label = str(ks.get("label", "")).strip()
                        value = ks.get("value")
                        unit = str(ks.get("unit", "")).strip()
                        if label and value is not None:
                            ks_lines.append(f"â€¢ {label}: {value} {unit}".rstrip())
                if len(ks_lines) > 1:
                    combined_lines.extend(ks_lines)
                    combined_lines.append("")

            readability = summary_shaped.get("readability") or {}
            if isinstance(readability, dict):
                method = readability.get("method")
                score = readability.get("score")
                level = readability.get("level")
                details = [str(x) for x in (method, score, level) if x is not None]
                if details:
                    combined_lines.append("ğŸ§® Readability: " + ", ".join(map(str, details)))
                    combined_lines.append("")

            seo = [
                str(x).strip() for x in (summary_shaped.get("seo_keywords") or []) if str(x).strip()
            ]
            if seo:
                combined_lines.append("ğŸ” SEO Keywords: " + ", ".join(seo[:20]))
                combined_lines.append("")

            # Metadata
            metadata = summary_shaped.get("metadata") or {}
            if isinstance(metadata, dict):
                meta_parts = []
                if metadata.get("title"):
                    meta_parts.append(f"ğŸ“° {metadata['title']}")
                if metadata.get("author"):
                    meta_parts.append(f"âœï¸ {metadata['author']}")
                if metadata.get("domain"):
                    meta_parts.append(f"ğŸŒ {metadata['domain']}")
                if meta_parts:
                    combined_lines.extend(meta_parts)
                    combined_lines.append("")

            # Categories & Topic Taxonomy
            categories = [
                str(c).strip() for c in (summary_shaped.get("categories") or []) if str(c).strip()
            ]
            if categories:
                combined_lines.append("ğŸ“ Categories: " + ", ".join(categories[:10]))
                combined_lines.append("")

            # Confidence & Risk
            confidence = summary_shaped.get("confidence", 1.0)
            risk = summary_shaped.get("hallucination_risk", "low")
            if isinstance(confidence, int | float) and confidence < 1.0:
                combined_lines.append(f"ğŸ¯ Confidence: {confidence:.1%}")
            if risk != "low":
                risk_emoji = "âš ï¸" if risk == "med" else "ğŸš¨"
                combined_lines.append(f"{risk_emoji} Hallucination risk: {risk}")
            if confidence < 1.0 or risk != "low":
                combined_lines.append("")

            if combined_lines:
                # Remove trailing empty lines
                while combined_lines and not combined_lines[-1]:
                    combined_lines.pop()
                await self._send_long_text(message, "\n".join(combined_lines))

            # Send separated summary fields (summary_250, summary_500, summary_1000, ...)
            summary_fields = [
                k
                for k in summary_shaped.keys()
                if k.startswith("summary_") and k.split("_", 1)[1].isdigit()
            ]

            def _key_num(k: str) -> int:
                try:
                    return int(k.split("_", 1)[1])
                except Exception:
                    return 0

            for key in sorted(summary_fields, key=_key_num):
                content = str(summary_shaped.get(key, "")).strip()
                if content:
                    content = self._sanitize_summary_text(content)
                    await self._send_long_text(
                        message,
                        f"ğŸ§¾ Summary {key.split('_', 1)[1]}:\n{content}",
                    )

            # Key ideas as separate messages
            ideas = [
                str(x).strip() for x in (summary_shaped.get("key_ideas") or []) if str(x).strip()
            ]
            if ideas:
                chunk: list[str] = []
                for idea in ideas:
                    chunk.append(f"â€¢ {idea}")
                    if sum(len(c) + 1 for c in chunk) > 3000:
                        await self._send_long_text(message, "ğŸ’¡ Key Ideas:\n" + "\n".join(chunk))
                        chunk = []
                if chunk:
                    await self._send_long_text(message, "ğŸ’¡ Key Ideas:\n" + "\n".join(chunk))

            # Send new field messages
            await self._send_new_field_messages(message, summary_shaped)

            # Finally attach full JSON as a document with a descriptive filename
            await self.reply_json(message, summary_shaped)

        except Exception:
            # Fallback to simpler format
            try:
                tl_dr = str(summary_shaped.get("summary_250", "")).strip()
                if tl_dr:
                    await self.safe_reply(message, f"ğŸ“‹ TL;DR:\n{tl_dr}")
            except Exception:
                pass

            await self.reply_json(message, summary_shaped)

    async def send_forward_summary_response(
        self, message: Any, forward_shaped: dict[str, Any]
    ) -> None:
        """Send forward summary with per-field messages, then attach full JSON file."""
        try:
            await self.safe_reply(message, "ğŸ‰ Forward Summary Ready")

            combined_lines: list[str] = []
            tl_dr = str(forward_shaped.get("summary_250", "")).strip()
            if tl_dr:
                tl_dr_clean = self._sanitize_summary_text(tl_dr)
                combined_lines.extend(["ğŸ“‹ TL;DR:", tl_dr_clean, ""])

            tags = [
                str(t).strip() for t in (forward_shaped.get("topic_tags") or []) if str(t).strip()
            ]
            if tags:
                combined_lines.append("ğŸ·ï¸ Tags: " + " ".join(tags))
                combined_lines.append("")

            entities = forward_shaped.get("entities") or {}
            if isinstance(entities, dict):
                people = [str(x).strip() for x in (entities.get("people") or []) if str(x).strip()]
                orgs = [
                    str(x).strip() for x in (entities.get("organizations") or []) if str(x).strip()
                ]
                locs = [str(x).strip() for x in (entities.get("locations") or []) if str(x).strip()]
                ent_parts: list[str] = []
                if people:
                    ent_parts.append("ğŸ‘¤ " + ", ".join(people[:10]))
                if orgs:
                    ent_parts.append("ğŸ¢ " + ", ".join(orgs[:10]))
                if locs:
                    ent_parts.append("ğŸŒ " + ", ".join(locs[:10]))
                if ent_parts:
                    combined_lines.append("ğŸ§­ Entities: " + " | ".join(ent_parts))
                    combined_lines.append("")

            reading_time = forward_shaped.get("estimated_reading_time_min")
            if reading_time:
                combined_lines.append(f"â±ï¸ Reading time: ~{reading_time} min")
                combined_lines.append("")

            key_stats = forward_shaped.get("key_stats") or []
            if isinstance(key_stats, list) and key_stats:
                ks_lines: list[str] = ["ğŸ“ˆ Key Stats:"]
                for ks in key_stats[:10]:
                    if isinstance(ks, dict):
                        label = str(ks.get("label", "")).strip()
                        value = ks.get("value")
                        unit = str(ks.get("unit", "")).strip()
                        if label and value is not None:
                            ks_lines.append(f"â€¢ {label}: {value} {unit}".rstrip())
                if len(ks_lines) > 1:
                    combined_lines.extend(ks_lines)
                    combined_lines.append("")

            readability = forward_shaped.get("readability") or {}
            if isinstance(readability, dict):
                method = readability.get("method")
                score = readability.get("score")
                level = readability.get("level")
                details = [str(x) for x in (method, score, level) if x is not None]
                if details:
                    combined_lines.append("ğŸ§® Readability: " + ", ".join(map(str, details)))
                    combined_lines.append("")

            seo = [
                str(x).strip() for x in (forward_shaped.get("seo_keywords") or []) if str(x).strip()
            ]
            if seo:
                combined_lines.append("ğŸ” SEO Keywords: " + ", ".join(seo[:20]))
                combined_lines.append("")

            # Metadata for forward posts
            metadata = forward_shaped.get("metadata") or {}
            if isinstance(metadata, dict):
                meta_parts = []
                if metadata.get("title"):
                    meta_parts.append(f"ğŸ“° {metadata['title']}")
                if metadata.get("author"):
                    meta_parts.append(f"âœï¸ {metadata['author']}")
                if meta_parts:
                    combined_lines.extend(meta_parts)
                    combined_lines.append("")

            # Categories & Risk for forwards
            categories = [
                str(c).strip() for c in (forward_shaped.get("categories") or []) if str(c).strip()
            ]
            if categories:
                combined_lines.append("ğŸ“ Categories: " + ", ".join(categories[:10]))
                combined_lines.append("")

            confidence = forward_shaped.get("confidence", 1.0)
            risk = forward_shaped.get("hallucination_risk", "low")
            if isinstance(confidence, int | float) and confidence < 1.0:
                combined_lines.append(f"ğŸ¯ Confidence: {confidence:.1%}")
            if risk != "low":
                risk_emoji = "âš ï¸" if risk == "med" else "ğŸš¨"
                combined_lines.append(f"{risk_emoji} Hallucination risk: {risk}")
            if confidence < 1.0 or risk != "low":
                combined_lines.append("")

            if combined_lines:
                # Remove trailing empty lines
                while combined_lines and not combined_lines[-1]:
                    combined_lines.pop()
                await self._send_long_text(message, "\n".join(combined_lines))

            # Separated summary fields
            summary_fields = [
                k
                for k in forward_shaped.keys()
                if k.startswith("summary_") and k.split("_", 1)[1].isdigit()
            ]

            def _key_num_f(k: str) -> int:
                try:
                    return int(k.split("_", 1)[1])
                except Exception:
                    return 0

            for key in sorted(summary_fields, key=_key_num_f):
                content = str(forward_shaped.get(key, "")).strip()
                if content:
                    content = self._sanitize_summary_text(content)
                    await self._send_long_text(
                        message,
                        f"ğŸ§¾ Summary {key.split('_', 1)[1]}:\n{content}",
                    )

            ideas = [
                str(x).strip() for x in (forward_shaped.get("key_ideas") or []) if str(x).strip()
            ]
            if ideas:
                await self._send_long_text(
                    message, "ğŸ’¡ Key Ideas:\n" + "\n".join([f"â€¢ {i}" for i in ideas])
                )

            # Send new field messages for forwards
            await self._send_new_field_messages(message, forward_shaped)
        except Exception:
            pass

        await self.reply_json(message, forward_shaped)

    async def reply_json(self, message: Any, obj: dict) -> None:
        """Reply with JSON object, using file upload for large content."""
        if self._reply_json_func is not None:
            await self._reply_json_func(message, obj)
            return

        pretty = json.dumps(obj, ensure_ascii=False, indent=2)
        # Prefer sending as a document always to avoid size limits
        try:
            bio = io.BytesIO(pretty.encode("utf-8"))
            bio.name = self._build_json_filename(obj)
            msg_any: Any = message
            await msg_any.reply_document(bio, caption="ğŸ“Š Full Summary JSON attached")
            return
        except Exception as e:  # noqa: BLE001
            logger.error("reply_document_failed", extra={"error": str(e)})
        await self.safe_reply(message, f"```json\n{pretty}\n```")

    async def safe_reply(self, message: Any, text: str, *, parse_mode: str | None = None) -> None:
        """Safely reply to a message with error handling."""
        if self._safe_reply_func is not None:
            kwargs = {"parse_mode": parse_mode} if parse_mode is not None else {}
            await self._safe_reply_func(message, text, **kwargs)
            return

        try:
            msg_any: Any = message
            if parse_mode:
                await msg_any.reply_text(text, parse_mode=parse_mode)
            else:
                await msg_any.reply_text(text)
            try:
                logger.debug("reply_text_sent", extra={"length": len(text)})
            except Exception:
                pass
        except Exception as e:  # noqa: BLE001
            logger.error("reply_failed", extra={"error": str(e)})

    async def send_url_accepted_notification(
        self, message: Any, norm: str, correlation_id: str
    ) -> None:
        """Send URL accepted notification."""
        try:
            from urllib.parse import urlparse

            url_domain = urlparse(norm).netloc if norm else "unknown"
            await self.safe_reply(
                message,
                f"âœ… **Request Accepted**\n"
                f"ğŸŒ Domain: `{url_domain}`\n"
                f"ğŸ”— URL: `{norm[:60]}{'...' if len(norm) > 60 else ''}`\n"
                f"ğŸ“‹ Status: Fetching content...\n"
                f"ğŸ¤– Enhanced: Structured output with smart fallbacks",
            )
        except Exception:
            pass

    def _slugify(self, text: str, *, max_len: int = 60) -> str:
        """Create a filesystem-friendly slug from text."""
        text = text.strip().lower()
        # Replace non-word characters with hyphens
        text = re.sub(r"[^\w\-\s]", "", text)
        text = re.sub(r"[\s_]+", "-", text)
        text = re.sub(r"-+", "-", text).strip("-")
        if len(text) > max_len:
            text = text[:max_len].rstrip("-")
        return text or "summary"

    async def _send_long_text(self, message: Any, text: str) -> None:
        """Send text, splitting into multiple messages if too long for Telegram."""
        max_len = 3500
        if len(text) <= max_len:
            await self.safe_reply(message, text)
            return
        # Split on paragraph boundaries
        parts = text.split("\n\n")
        buf: list[str] = []
        length = 0
        for p in parts:
            seg = (p + "\n\n") if p else "\n\n"
            if length + len(seg) > max_len and buf:
                await self.safe_reply(message, "".join(buf).rstrip())
                buf = []
                length = 0
            buf.append(seg)
            length += len(seg)
        if buf:
            await self.safe_reply(message, "".join(buf).rstrip())

    def _build_json_filename(self, obj: dict) -> str:
        """Build a descriptive filename for the JSON attachment."""
        # Prefer SEO keywords; fallback to first words of TL;DR
        seo = obj.get("seo_keywords") or []
        base: str | None = None
        if isinstance(seo, list) and seo:
            base = "-".join(self._slugify(str(x)) for x in seo[:3] if str(x).strip())
        if not base:
            tl = str(obj.get("summary_250", "")).strip()
            if tl:
                # Use first 6 words
                words = re.findall(r"\w+", tl)[:6]
                base = self._slugify("-".join(words))
        if not base:
            base = "summary"
        timestamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
        return f"{base}-{timestamp}.json"

    def _format_bytes(self, size: int) -> str:
        """Convert byte count into a human-readable string."""
        units = ["B", "KB", "MB", "GB", "TB"]
        value = float(size)
        for unit in units:
            if value < 1024 or unit == units[-1]:
                if unit == "B":
                    return f"{int(value)} {unit}"
                return f"{value:.1f} {unit}"
            value /= 1024
        return f"{value:.1f} TB"

    def _sanitize_summary_text(self, text: str) -> str:
        """Normalize and clean summary text for safe sending.

        - Normalize to NFC
        - Remove control characters
        - Drop trailing isolated CJK run (1-3 chars) that looks like a stray token
        """
        try:
            s = unicodedata.normalize("NFC", text)
        except Exception:
            s = text
        # Remove control and non-printable chars
        s = "".join(ch for ch in s if unicodedata.category(ch)[0] != "C")

        # If string ends with 1-3 CJK chars and preceding 15 chars have no CJK, drop the tail
        tail_match = re.search(r"([\u4E00-\u9FFF]{1,3})$", s)
        if tail_match:
            start = max(0, len(s) - 20)
            window = s[start : len(s) - len(tail_match.group(1))]
            if not re.search(r"[\u4E00-\u9FFF]", window):
                s = s[: -len(tail_match.group(1))].rstrip("-â€”")

        return s.strip()

    async def _send_new_field_messages(self, message: Any, shaped: dict[str, Any]) -> None:
        """Send messages for new fields like extractive quotes, highlights, etc."""
        try:
            # Extractive quotes
            quotes = shaped.get("extractive_quotes") or []
            if isinstance(quotes, list) and quotes:
                quote_lines = ["ğŸ’¬ Key Quotes:"]
                for i, quote in enumerate(quotes[:5], 1):
                    if isinstance(quote, dict) and quote.get("text"):
                        text = str(quote["text"]).strip()
                        if text:
                            quote_lines.append(f'{i}. "{text}"')
                if len(quote_lines) > 1:
                    await self._send_long_text(message, "\n".join(quote_lines))

            # Highlights
            highlights = [
                str(h).strip() for h in (shaped.get("highlights") or []) if str(h).strip()
            ]
            if highlights:
                await self._send_long_text(
                    message, "âœ¨ Highlights:\n" + "\n".join([f"â€¢ {h}" for h in highlights[:10]])
                )

            # Questions answered
            questions = [
                str(q).strip() for q in (shaped.get("questions_answered") or []) if str(q).strip()
            ]
            if questions:
                await self._send_long_text(
                    message,
                    "â“ Questions Answered:\n" + "\n".join([f"â€¢ {q}" for q in questions[:10]]),
                )

            # Key points to remember
            key_points = [
                str(kp).strip()
                for kp in (shaped.get("key_points_to_remember") or [])
                if str(kp).strip()
            ]
            if key_points:
                await self._send_long_text(
                    message,
                    "ğŸ¯ Key Points to Remember:\n"
                    + "\n".join([f"â€¢ {kp}" for kp in key_points[:10]]),
                )

            # Topic taxonomy (if present and not empty)
            taxonomy = shaped.get("topic_taxonomy") or []
            if isinstance(taxonomy, list) and taxonomy:
                tax_lines = ["ğŸ·ï¸ Topic Classification:"]
                for tax in taxonomy[:5]:
                    if isinstance(tax, dict) and tax.get("label"):
                        label = str(tax["label"]).strip()
                        score = tax.get("score", 0.0)
                        if isinstance(score, int | float) and score > 0:
                            tax_lines.append(f"â€¢ {label} ({score:.1%})")
                        else:
                            tax_lines.append(f"â€¢ {label}")
                if len(tax_lines) > 1:
                    await self._send_long_text(message, "\n".join(tax_lines))

            # Forwarded post extras
            fwd_extras = shaped.get("forwarded_post_extras")
            if isinstance(fwd_extras, dict):
                fwd_parts = []
                if fwd_extras.get("channel_title"):
                    fwd_parts.append(f"ğŸ“º Channel: {fwd_extras['channel_title']}")
                if fwd_extras.get("channel_username"):
                    fwd_parts.append(f"@{fwd_extras['channel_username']}")
                hashtags = [
                    str(h).strip() for h in (fwd_extras.get("hashtags") or []) if str(h).strip()
                ]
                if hashtags:
                    fwd_parts.append(
                        "Tags: "
                        + " ".join([f"#{h}" if not h.startswith("#") else h for h in hashtags[:5]])
                    )
                if fwd_parts:
                    await self._send_long_text(message, "ğŸ“¤ Forward Info:\n" + "\n".join(fwd_parts))

        except Exception:
            pass

    async def send_firecrawl_start_notification(self, message: Any) -> None:
        """Send Firecrawl start notification."""
        try:
            await self.safe_reply(
                message,
                "ğŸ•·ï¸ **Firecrawl Extraction**\n"
                "ğŸ“¡ Connecting to Firecrawl API...\n"
                "â±ï¸ This may take 10-30 seconds\n"
                "ğŸ”„ Enhanced processing pipeline active",
            )
        except Exception:
            pass

    async def send_firecrawl_success_notification(
        self, message: Any, excerpt_len: int, latency_sec: float
    ) -> None:
        """Send Firecrawl success notification."""
        try:
            await self.safe_reply(
                message,
                f"âœ… **Content Extracted Successfully**\n"
                f"ğŸ“Š Size: ~{excerpt_len:,} characters\n"
                f"â±ï¸ Extraction time: {latency_sec:.1f}s\n"
                f"ğŸ”„ Status: Preparing for enhanced AI analysis...",
            )
        except Exception:
            pass

    async def send_content_reuse_notification(self, message: Any) -> None:
        """Send content reuse notification."""
        try:
            await self.safe_reply(
                message,
                "â™»ï¸ **Reusing Cached Content**\n"
                "ğŸ“Š Status: Content already extracted\n"
                "âš¡ Proceeding to enhanced AI analysis...",
            )
        except Exception:
            pass

    async def send_html_fallback_notification(self, message: Any, content_len: int) -> None:
        """Send HTML fallback notification."""
        try:
            await self.safe_reply(
                message,
                f"ğŸ”„ **Content Processing Update**\n"
                f"ğŸ“„ Markdown extraction was empty\n"
                f"ğŸ› ï¸ Using HTML content extraction\n"
                f"ğŸ“Š Processing {content_len:,} characters...\n"
                f"ğŸ¤– Enhanced pipeline will optimize for best results",
            )
        except Exception:
            pass

    async def send_language_detection_notification(
        self, message: Any, detected: str | None, content_preview: str
    ) -> None:
        """Send language detection notification."""
        try:
            await self.safe_reply(
                message,
                f"ğŸŒ **Language Detection**\n"
                f"ğŸ“ Detected: `{detected or 'unknown'}`\n"
                f"ğŸ“„ Content preview:\n"
                f"```\n{content_preview}\n```\n"
                f"ğŸ¤– Status: Preparing enhanced AI analysis with structured outputs...",
            )
        except Exception:
            pass

    async def send_content_analysis_notification(
        self,
        message: Any,
        content_len: int,
        max_chars: int,
        enable_chunking: bool,
        chunks: list[str] | None,
        structured_output_mode: str,
    ) -> None:
        """Send content analysis notification."""
        try:
            if enable_chunking and content_len > max_chars and (chunks or []):
                await self.safe_reply(
                    message,
                    f"ğŸ“š **Enhanced Content Analysis**\n"
                    f"ğŸ“Š Length: {content_len:,} characters\n"
                    f"ğŸ”€ Processing: Chunked analysis ({len(chunks or [])} chunks)\n"
                    f"ğŸ¤– Method: Advanced structured output with schema validation\n"
                    f"âš¡ Status: Sending to AI model with smart fallbacks...",
                )
            elif not enable_chunking and content_len > max_chars:
                await self.safe_reply(
                    message,
                    f"ğŸ“š **Enhanced Content Analysis**\n"
                    f"ğŸ“Š Length: {content_len:,} characters (exceeds {max_chars:,} adaptive threshold)\n"
                    f"ğŸ”€ Processing: Single-pass (chunking disabled)\n"
                    f"ğŸ¤– Method: Enhanced structured output with intelligent fallbacks\n"
                    f"âš¡ Status: Sending to AI model...",
                )
            else:
                await self.safe_reply(
                    message,
                    f"ğŸ“š **Enhanced Content Analysis**\n"
                    f"ğŸ“Š Length: {content_len:,} characters\n"
                    f"ğŸ”€ Processing: Single-pass summary\n"
                    f"ğŸ¤– Method: Structured output with schema validation\n"
                    f"âš¡ Status: Sending to AI model...",
                )
        except Exception:
            pass

    async def send_llm_start_notification(
        self, message: Any, model: str, content_len: int, structured_output_mode: str
    ) -> None:
        """Send LLM start notification."""
        try:
            await self.safe_reply(
                message,
                f"ğŸ¤– **Enhanced AI Analysis Starting**\n"
                f"ğŸ§  Model: `{model}`\n"
                f"ğŸ“Š Content: {content_len:,} characters\n"
                f"ğŸ”§ Mode: {structured_output_mode.upper()} with smart fallbacks\n"
                f"â±ï¸ This may take 30-60 seconds...",
            )
        except Exception:
            pass

    async def send_llm_completion_notification(
        self, message: Any, llm: Any, correlation_id: str
    ) -> None:
        """Send LLM completion notification."""
        try:
            model_name = llm.model or "unknown"
            latency_sec = (llm.latency_ms or 0) / 1000.0

            if llm.status == "ok":
                # Success message with enhanced details
                tokens_used = (llm.tokens_prompt or 0) + (llm.tokens_completion or 0)
                cost_info = f" (${llm.cost_usd:.4f})" if llm.cost_usd else ""
                structured_info = ""
                if hasattr(llm, "structured_output_used") and llm.structured_output_used:
                    mode = getattr(llm, "structured_output_mode", "unknown")
                    structured_info = f"\nğŸ”§ Structured Output: {mode.upper()}"

                await self.safe_reply(
                    message,
                    f"ğŸ¤– **Enhanced AI Analysis Complete**\n"
                    f"âœ… Status: Success\n"
                    f"ğŸ§  Model: `{model_name}`\n"
                    f"â±ï¸ Processing time: {latency_sec:.1f}s\n"
                    f"ğŸ”¢ Tokens used: {tokens_used:,}{cost_info}{structured_info}\n"
                    f"ğŸ“‹ Status: Generating enhanced summary...",
                )
            else:
                # Enhanced error message
                await self.safe_reply(
                    message,
                    f"ğŸ¤– **Enhanced AI Analysis Failed**\n"
                    f"âŒ Status: Error\n"
                    f"ğŸ§  Model: `{model_name}`\n"
                    f"â±ï¸ Processing time: {latency_sec:.1f}s\n"
                    f"ğŸš¨ Error: {llm.error_text or 'Unknown error'}\n"
                    f"ğŸ”„ Smart fallbacks: Active\n"
                    f"ğŸ†” Error ID: `{correlation_id}`",
                )
        except Exception:
            pass

    async def send_forward_accepted_notification(self, message: Any, title: str) -> None:
        """Send forward request accepted notification."""
        try:
            await self.safe_reply(
                message,
                "âœ… **Forward Request Accepted**\n"
                f"ğŸ“º Channel: {title}\n"
                "ğŸ¤– Enhanced processing with structured outputs...\n"
                "ğŸ“‹ Status: Generating summary...",
            )
        except Exception:
            pass

    async def send_forward_language_notification(self, message: Any, detected: str | None) -> None:
        """Send forward language detection notification."""
        try:
            await self.safe_reply(
                message,
                f"ğŸŒ **Language Detection**\n"
                f"ğŸ“ Detected: `{detected or 'unknown'}`\n"
                f"ğŸ¤– Processing with enhanced structured outputs...\n"
                f"âš¡ Status: Sending to AI model...",
            )
        except Exception:
            pass

    async def send_forward_completion_notification(self, message: Any, llm: Any) -> None:
        """Send forward completion notification."""
        try:
            status_emoji = "âœ…" if llm.status == "ok" else "âŒ"
            latency_sec = (llm.latency_ms or 0) / 1000.0
            structured_info = ""
            if hasattr(llm, "structured_output_used") and llm.structured_output_used:
                mode = getattr(llm, "structured_output_mode", "unknown")
                structured_info = f"\nğŸ”§ Schema: {mode.upper()}"

            await self.safe_reply(
                message,
                f"ğŸ¤– **Enhanced AI Analysis Complete**\n"
                f"{status_emoji} Status: {'Success' if llm.status == 'ok' else 'Error'}\n"
                f"â±ï¸ Time: {latency_sec:.1f}s{structured_info}\n"
                f"ğŸ“‹ Status: {'Generating summary...' if llm.status == 'ok' else 'Processing error...'}",
            )
        except Exception:
            pass

    async def send_error_notification(
        self, message: Any, error_type: str, correlation_id: str, details: str | None = None
    ) -> None:
        """Send error notification with enhanced formatting."""
        try:
            if error_type == "firecrawl_error":
                await self.safe_reply(
                    message,
                    f"âŒ **Content Extraction Failed**\n"
                    f"ğŸš¨ Unable to extract readable content\n"
                    f"ğŸ†” Error ID: `{correlation_id}`\n\n"
                    f"ğŸ’¡ **Possible Solutions:**\n"
                    f"â€¢ Try a different URL\n"
                    f"â€¢ Check if content is publicly accessible\n"
                    f"â€¢ Ensure URL points to text-based content",
                )
            elif error_type == "empty_content":
                await self.safe_reply(
                    message,
                    f"âŒ **Content Extraction Failed**\n\n"
                    f"ğŸš¨ **Possible Causes:**\n"
                    f"â€¢ Website blocking automated access\n"
                    f"â€¢ Content behind paywall/login\n"
                    f"â€¢ Non-text content (images, videos)\n"
                    f"â€¢ Temporary server issues\n"
                    f"â€¢ Invalid or inaccessible URL\n\n"
                    f"ğŸ’¡ **Suggestions:**\n"
                    f"â€¢ Try a different URL\n"
                    f"â€¢ Check if content is publicly accessible\n"
                    f"â€¢ Ensure URL points to text-based content\n\n"
                    f"ğŸ†” Error ID: `{correlation_id}`",
                )
            elif error_type == "processing_failed":
                detail_block = f"\nğŸ” Reason: {details}" if details else ""
                if self._safe_reply_func is not None:
                    await self._safe_reply_func(
                        message,
                        f"Invalid summary format. Error ID: {correlation_id}{detail_block}",
                    )
                else:
                    await self.safe_reply(
                        message,
                        f"âŒ **Enhanced Processing Failed**\n"
                        f"ğŸš¨ Invalid summary format despite smart fallbacks{detail_block}\n"
                        f"ğŸ†” Error ID: `{correlation_id}`",
                    )
            elif error_type == "llm_error":
                detail_block = f"\nğŸ” Provider response: {details}" if details else ""
                await self.safe_reply(
                    message,
                    f"âŒ **Enhanced Processing Failed**\n"
                    f"ğŸš¨ LLM error despite smart fallbacks{detail_block}\n"
                    f"ğŸ†” Error ID: `{correlation_id}`",
                )
            else:
                # Generic error
                await self.safe_reply(
                    message,
                    f"âŒ **Error Occurred**\n"
                    f"ğŸš¨ {details or 'Unknown error'}\n"
                    f"ğŸ†” Error ID: `{correlation_id}`",
                )
        except Exception:
            pass
