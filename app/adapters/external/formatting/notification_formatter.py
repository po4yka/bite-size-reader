"""Status notification formatting."""

from __future__ import annotations

from typing import TYPE_CHECKING, Any

if TYPE_CHECKING:
    from collections.abc import Awaitable, Callable

    from app.adapters.external.formatting.data_formatter import DataFormatterImpl
    from app.adapters.external.formatting.response_sender import ResponseSenderImpl


class NotificationFormatterImpl:
    """Implementation of status notifications."""

    def __init__(
        self,
        response_sender: ResponseSenderImpl,
        data_formatter: DataFormatterImpl,
        *,
        safe_reply_func: Callable[[Any, str], Awaitable[None]] | None = None,
    ) -> None:
        """Initialize the notification formatter.

        Args:
            response_sender: Response sender for sending messages.
            data_formatter: Data formatter for formatting values.
            safe_reply_func: Optional callback for test compatibility.
        """
        self._response_sender = response_sender
        self._data_formatter = data_formatter
        self._safe_reply_func = safe_reply_func
        # Error notification deduplication
        self._notified_error_ids: set[str] = set()

    async def send_help(self, message: Any) -> None:
        """Send help message to user."""
        help_text = (
            "ğŸ¤– **Bite-Size Reader**\n\n"
            "ğŸ“‹ **Available Commands:**\n"
            "â€¢ `/start` â€” Welcome message and instructions\n"
            "â€¢ `/help` â€” Show this help message\n"
            "â€¢ `/summarize <URL>` â€” Summarize a URL\n"
            "â€¢ `/summarize_all <URLs>` â€” Summarize multiple URLs from one message\n"
            "â€¢ `/findweb <topic>` â€” Search the web (Firecrawl) for recent articles\n"
            "â€¢ `/finddb <topic>` â€” Search your saved Bite-Size Reader library\n"
            "â€¢ `/find <topic>` â€” Alias for `/findweb`\n"
            "â€¢ `/cancel` â€” Cancel any pending URL or multi-link requests\n"
            "â€¢ `/unread [topic] [limit]` â€” Show unread articles optionally filtered by topic\n"
            "â€¢ `/read <ID>` â€” Mark article as read and view it\n"
            "â€¢ `/dbinfo` â€” Show database overview\n\n"
            "â€¢ `/dbverify` â€” Verify stored posts and required fields\n\n"
            "ğŸ’¡ **Usage Tips:**\n"
            "â€¢ Send URLs directly (commands are optional)\n"
            "â€¢ Forward channel posts to summarize them\n"
            "â€¢ Send `/summarize` and then a URL in the next message\n"
            "â€¢ Upload a .txt file with URLs (one per line) for batch processing\n"
            "â€¢ Multiple links in one message are supported\n"
            "â€¢ Use `/unread [topic] [limit]` to see saved articles by topic\n\n"
            "âš¡ **Features:**\n"
            "â€¢ Structured JSON output with schema validation\n"
            "â€¢ Intelligent model fallbacks for better reliability\n"
            "â€¢ Automatic content optimization based on model capabilities\n"
            "â€¢ Silent batch processing for uploaded files\n"
            "â€¢ Progress tracking for multiple URLs"
        )
        await self._response_sender.safe_reply(message, help_text)

    async def send_welcome(self, message: Any) -> None:
        """Send welcome message to user."""
        welcome = (
            "Welcome to Bite-Size Reader!\n\n"
            "What I do:\n"
            "- Summarize articles from URLs using Firecrawl + OpenRouter.\n"
            "- Summarize forwarded channel posts.\n"
            "- Generate structured JSON summaries with reliable results.\n\n"
            "How to use:\n"
            "- Send a URL directly, or use /summarize <URL>.\n"
            "- You can also send /summarize and then the URL in the next message.\n"
            "- For forwarded posts, use /summarize_forward and then forward a channel post.\n"
            '- Multiple links in one message are supported: I will ask "Process N links?" or use /summarize_all to process immediately.\n'
            "- /dbinfo shares a quick snapshot of the internal database so you can monitor storage.\n\n"
            "Notes:\n"
            "- I reply with a strict JSON object using advanced schema validation.\n"
            "- Intelligent model selection and fallbacks ensure high success rates.\n"
            "- Errors include an Error ID you can reference in logs."
        )
        await self._response_sender.safe_reply(message, welcome)

    async def send_url_accepted_notification(
        self, message: Any, norm: str, correlation_id: str, *, silent: bool = False
    ) -> None:
        """Send URL accepted notification."""
        if silent:
            return

        try:
            from urllib.parse import urlparse

            url_domain = urlparse(norm).netloc if norm else "unknown"
            await self._response_sender.safe_reply(
                message,
                f"âœ… **Request Accepted**\n"
                f"ğŸŒ Domain: `{url_domain}`\n"
                f"ğŸ”— URL: `{norm[:60]}{'...' if len(norm) > 60 else ''}`\n"
                f"ğŸ“‹ Status: Fetching content...\n"
                f"ğŸ¤– Structured output with smart fallbacks",
            )
        except Exception:
            pass

    async def send_firecrawl_start_notification(
        self, message: Any, url: str | None = None, *, silent: bool = False
    ) -> None:
        """Send Firecrawl start notification."""
        if silent:
            return

        try:
            # Format URL for display (truncate if too long)
            url_display = ""
            if url:
                # Extract domain or truncate URL
                url_display = f"\nğŸ”— {url[:57]}..." if len(url) > 60 else f"\nğŸ”— {url}"

            await self._response_sender.safe_reply(
                message,
                f"ğŸ•·ï¸ **Firecrawl Extraction**{url_display}\n"
                "ğŸ“¡ Connecting to Firecrawl API...\n"
                "â±ï¸ This may take 10-30 seconds\n"
                "ğŸ”„ Processing pipeline active",
            )
        except Exception:
            pass

    async def send_firecrawl_success_notification(
        self,
        message: Any,
        excerpt_len: int,
        latency_sec: float,
        *,
        http_status: int | None = None,
        crawl_status: str | None = None,
        correlation_id: str | None = None,
        endpoint: str | None = None,
        options: dict[str, Any] | None = None,
        silent: bool = False,
    ) -> None:
        """Send Firecrawl success notification with crawl metadata."""
        if silent:
            return

        try:
            lines = [
                "âœ… **Content Extracted Successfully**",
                f"ğŸ“Š Size: ~{excerpt_len:,} characters",
                f"â±ï¸ Extraction time: {latency_sec:.1f}s",
            ]

            status_bits: list[str] = []
            if http_status is not None:
                status_bits.append(f"HTTP {http_status}")
            if crawl_status:
                status_bits.append(crawl_status)
            if status_bits:
                lines.append("ğŸ“¶ Firecrawl: " + " | ".join(status_bits))

            if endpoint:
                lines.append(f"ğŸŒ Endpoint: {endpoint}")

            option_line = self._data_formatter.format_firecrawl_options(options)
            if option_line:
                lines.append(f"âš™ï¸ Options: {option_line}")

            if correlation_id:
                lines.append(f"ğŸ†” Firecrawl CID: `{correlation_id}`")

            lines.append("ğŸ”„ Status: Preparing for AI analysis...")

            await self._response_sender.safe_reply(message, "\n".join(lines))
        except Exception:
            pass

    async def send_content_reuse_notification(
        self,
        message: Any,
        *,
        http_status: int | None = None,
        crawl_status: str | None = None,
        latency_sec: float | None = None,
        correlation_id: str | None = None,
        options: dict[str, Any] | None = None,
        silent: bool = False,
    ) -> None:
        """Send content reuse notification with cached crawl metadata."""
        if silent:
            return
        try:
            lines = [
                "â™»ï¸ **Reusing Cached Content**",
                "ğŸ“Š Status: Content already extracted",
            ]

            status_bits: list[str] = []
            if http_status is not None:
                status_bits.append(f"HTTP {http_status}")
            if crawl_status:
                status_bits.append(crawl_status)
            if status_bits:
                lines.append("ğŸ“¶ Firecrawl (cached): " + " | ".join(status_bits))

            if latency_sec is not None:
                lines.append(f"â±ï¸ Original extraction: {latency_sec:.1f}s")

            option_line = self._data_formatter.format_firecrawl_options(options)
            if option_line:
                lines.append(f"âš™ï¸ Options: {option_line}")

            if correlation_id:
                lines.append(f"ğŸ†” Firecrawl CID: `{correlation_id}`")

            lines.append("âš¡ Proceeding to AI analysis...")

            await self._response_sender.safe_reply(message, "\n".join(lines))
        except Exception:
            pass

    async def send_cached_summary_notification(self, message: Any, *, silent: bool = False) -> None:
        """Inform the user that a cached summary is being reused."""
        if silent:
            return
        try:
            await self._response_sender.safe_reply(
                message,
                "â™»ï¸ **Using Cached Summary**\nâš¡ Delivered instantly without extra processing",
            )
        except Exception:
            pass

    async def send_html_fallback_notification(
        self, message: Any, content_len: int, *, silent: bool = False
    ) -> None:
        """Send HTML fallback notification."""
        if silent:
            return
        try:
            await self._response_sender.safe_reply(
                message,
                f"ğŸ”„ **Content Processing Update**\n"
                f"ğŸ“„ Markdown extraction was empty\n"
                f"ğŸ› ï¸ Using HTML content extraction\n"
                f"ğŸ“Š Processing {content_len:,} characters...\n"
                f"ğŸ¤– Pipeline will optimize for best results",
            )
        except Exception:
            pass

    async def send_language_detection_notification(
        self,
        message: Any,
        detected: str | None,
        content_preview: str,
        *,
        url: str | None = None,
        silent: bool = False,
    ) -> None:
        """Send language detection notification."""
        if silent:
            return
        try:
            # Format URL for display (extract domain)
            url_line = ""
            if url:
                try:
                    from urllib.parse import urlparse

                    parsed = urlparse(url)
                    domain = parsed.netloc or parsed.path.split("/")[0] if parsed.path else url
                    # Clean up domain
                    if domain.startswith("www."):
                        domain = domain[4:]
                    if domain and len(domain) <= 40:
                        url_line = f"ğŸ”— Source: {domain}\n"
                except Exception:
                    pass

            await self._response_sender.safe_reply(
                message,
                f"ğŸŒ **Language Detection**\n"
                f"{url_line}"
                f"ğŸ“ Detected: `{detected or 'unknown'}`\n"
                f"ğŸ“„ Content preview:\n"
                f"```\n{content_preview}\n```\n"
                f"ğŸ¤– Status: Preparing AI analysis with structured outputs...",
            )
        except Exception:
            pass

    async def send_content_analysis_notification(
        self,
        message: Any,
        content_len: int,
        max_chars: int,
        enable_chunking: bool,
        chunks: list[str] | None,
        structured_output_mode: str,
        *,
        silent: bool = False,
    ) -> None:
        """Send content analysis notification."""
        if silent:
            return
        try:
            if enable_chunking and content_len > max_chars and (chunks or []):
                await self._response_sender.safe_reply(
                    message,
                    f"ğŸ“š **Content Analysis**\n"
                    f"ğŸ“Š Length: {content_len:,} characters\n"
                    f"ğŸ”€ Processing: Chunked analysis ({len(chunks or [])} chunks)\n"
                    f"ğŸ¤– Method: Advanced structured output with schema validation\n"
                    f"âš¡ Status: Sending to AI model with smart fallbacks...",
                )
            elif not enable_chunking and content_len > max_chars:
                await self._response_sender.safe_reply(
                    message,
                    f"ğŸ“š **Content Analysis**\n"
                    f"ğŸ“Š Length: {content_len:,} characters (exceeds {max_chars:,} adaptive threshold)\n"
                    f"ğŸ”€ Processing: Single-pass (chunking disabled)\n"
                    f"ğŸ¤– Method: Structured output with intelligent fallbacks\n"
                    f"âš¡ Status: Sending to AI model...",
                )
            else:
                await self._response_sender.safe_reply(
                    message,
                    f"ğŸ“š **Content Analysis**\n"
                    f"ğŸ“Š Length: {content_len:,} characters\n"
                    f"ğŸ”€ Processing: Single-pass summary\n"
                    f"ğŸ¤– Method: Structured output with schema validation\n"
                    f"âš¡ Status: Sending to AI model...",
                )
        except Exception:
            pass

    async def send_llm_start_notification(
        self,
        message: Any,
        model: str,
        content_len: int,
        structured_output_mode: str,
        *,
        url: str | None = None,
        silent: bool = False,
    ) -> None:
        """Send LLM start notification."""
        if silent:
            return

        try:
            # Format URL for display (extract domain or truncate)
            url_line = ""
            if url:
                try:
                    from urllib.parse import urlparse

                    parsed = urlparse(url)
                    domain = parsed.netloc or parsed.path.split("/")[0] if parsed.path else url
                    # Clean up domain
                    if domain.startswith("www."):
                        domain = domain[4:]
                    if domain and len(domain) <= 40:
                        url_line = f"ğŸ”— Source: {domain}\n"
                    elif len(url) <= 50:
                        url_line = f"ğŸ”— {url}\n"
                    else:
                        url_line = f"ğŸ”— {url[:47]}...\n"
                except Exception:
                    # Fallback to simple truncation
                    url_line = f"ğŸ”— {url}\n" if len(url) <= 50 else f"ğŸ”— {url[:47]}...\n"

            await self._response_sender.safe_reply(
                message,
                f"ğŸ¤– **AI Analysis Starting**\n"
                f"{url_line}"
                f"ğŸ§  Model: `{model}`\n"
                f"ğŸ“Š Content: {content_len:,} characters\n"
                f"ğŸ”§ Mode: {structured_output_mode.upper()} with smart fallbacks\n"
                f"â±ï¸ This may take 30-60 seconds...",
            )
        except Exception:
            pass

    async def send_llm_completion_notification(
        self, message: Any, llm: Any, correlation_id: str, *, silent: bool = False
    ) -> None:
        """Send LLM completion notification."""
        if silent:
            return
        try:
            model_name = llm.model or "unknown"
            latency_sec = (llm.latency_ms or 0) / 1000.0

            if llm.status == "ok":
                prompt_tokens = llm.tokens_prompt or 0
                completion_tokens = llm.tokens_completion or 0
                tokens_used = prompt_tokens + completion_tokens

                lines = [
                    "ğŸ¤– **AI Analysis Complete**",
                    "âœ… Status: Success",
                    f"ğŸ§  Model: `{model_name}`",
                    f"â±ï¸ Processing time: {latency_sec:.1f}s",
                    (
                        "ğŸ”¢ Tokens â€” prompt: "
                        f"{prompt_tokens:,} â€¢ completion: {completion_tokens:,} "
                        f"(total: {tokens_used:,})"
                    ),
                ]

                if llm.cost_usd is not None:
                    lines.append(f"ğŸ’² Estimated cost: ${llm.cost_usd:.4f}")

                if getattr(llm, "structured_output_used", False):
                    mode = getattr(llm, "structured_output_mode", "unknown")
                    lines.append(f"ğŸ”§ Structured output: {mode.upper()}")

                if llm.endpoint:
                    lines.append(f"ğŸŒ Endpoint: {llm.endpoint}")

                if correlation_id:
                    lines.append(f"ğŸ†” Request ID: `{correlation_id}`")

                lines.append("ğŸ“‹ Status: Generating summary...")

                await self._response_sender.safe_reply(message, "\n".join(lines))
            else:
                # Error message for failure scenarios
                await self._response_sender.safe_reply(
                    message,
                    f"ğŸ¤– **AI Analysis Failed**\n"
                    f"âŒ Status: Error\n"
                    f"ğŸ§  Model: `{model_name}`\n"
                    f"â±ï¸ Processing time: {latency_sec:.1f}s\n"
                    f"ğŸš¨ Error: {llm.error_text or 'Unknown error'}\n"
                    f"ğŸ”„ Smart fallbacks: Active\n"
                    f"ğŸ†” Error ID: `{correlation_id}`",
                )
        except Exception:
            pass

    async def send_forward_accepted_notification(self, message: Any, title: str) -> None:
        """Send forward request accepted notification."""
        try:
            await self._response_sender.safe_reply(
                message,
                "âœ… **Forward Request Accepted**\n"
                f"ğŸ“º Channel: {title}\n"
                "ğŸ¤– Processing with structured outputs...\n"
                "ğŸ“‹ Status: Generating summary...",
            )
        except Exception:
            pass

    async def send_forward_language_notification(self, message: Any, detected: str | None) -> None:
        """Send forward language detection notification."""
        try:
            await self._response_sender.safe_reply(
                message,
                f"ğŸŒ **Language Detection**\n"
                f"ğŸ“ Detected: `{detected or 'unknown'}`\n"
                f"ğŸ¤– Processing with structured outputs...\n"
                f"âš¡ Status: Sending to AI model...",
            )
        except Exception:
            pass

    async def send_forward_completion_notification(self, message: Any, llm: Any) -> None:
        """Send forward completion notification."""
        try:
            status_emoji = "âœ…" if llm.status == "ok" else "âŒ"
            latency_sec = (llm.latency_ms or 0) / 1000.0
            structured_info = ""
            if hasattr(llm, "structured_output_used") and llm.structured_output_used:
                mode = getattr(llm, "structured_output_mode", "unknown")
                structured_info = f"\nğŸ”§ Schema: {mode.upper()}"

            await self._response_sender.safe_reply(
                message,
                f"ğŸ¤– **AI Analysis Complete**\n"
                f"{status_emoji} Status: {'Success' if llm.status == 'ok' else 'Error'}\n"
                f"â±ï¸ Time: {latency_sec:.1f}s{structured_info}\n"
                f"ğŸ“‹ Status: {'Generating summary...' if llm.status == 'ok' else 'Processing error...'}",
            )
        except Exception:
            pass

    async def send_youtube_download_notification(
        self, message: Any, url: str, *, silent: bool = False
    ) -> None:
        """Notify user that YouTube video download is starting."""
        if silent:
            return

        try:
            await self._response_sender.safe_reply(
                message,
                "ğŸ¥ **YouTube Video Detected**\n\n"
                "ğŸ“¥ Downloading video in 1080p and extracting transcript...\n"
                "â±ï¸ This may take a few minutes depending on video length.\n\n"
                f"ğŸ”— URL: {url[:60]}{'...' if len(url) > 60 else ''}",
            )
        except Exception:
            pass

    async def send_youtube_download_complete_notification(
        self,
        message: Any,
        title: str,
        resolution: str,
        size_mb: float,
        *,
        silent: bool = False,
    ) -> None:
        """Notify user that video download is complete."""
        if silent:
            return

        try:
            await self._response_sender.safe_reply(
                message,
                "âœ… **Video Downloaded Successfully!**\n\n"
                f"ğŸ“¹ Title: {title[:80]}{'...' if len(title) > 80 else ''}\n"
                f"ğŸ“º Resolution: {resolution}\n"
                f"ğŸ’¾ Size: {size_mb:.1f} MB\n\n"
                "ğŸ¤– Generating summary from transcript...",
            )
        except Exception:
            pass

    async def send_error_notification(
        self,
        message: Any,
        error_type: str,
        correlation_id: str,
        details: str | None = None,
    ) -> None:
        """Send error notification with rich formatting."""
        # Deduplication: check if we've already sent a notification for this error ID
        if correlation_id and correlation_id in self._notified_error_ids:
            return

        # Mark this error ID as notified
        if correlation_id:
            self._notified_error_ids.add(correlation_id)

        try:
            if error_type == "firecrawl_error":
                details_block = f"\n\n{details}" if details else ""
                await self._response_sender.safe_reply(
                    message,
                    (
                        "âŒ **Content Extraction Failed**\n"
                        "ğŸš¨ Unable to extract readable content\n"
                        f"ğŸ†” Error ID: `{correlation_id}`"
                        f"{details_block}\n\n"
                        "ğŸ’¡ **Possible Solutions:**\n"
                        "â€¢ Try a different URL\n"
                        "â€¢ Check if content is publicly accessible\n"
                        "â€¢ Ensure URL points to text-based content"
                    ),
                )
            elif error_type == "empty_content":
                await self._response_sender.safe_reply(
                    message,
                    f"âŒ **Content Extraction Failed**\n\n"
                    f"ğŸš¨ **Possible Causes:**\n"
                    f"â€¢ Website blocking automated access\n"
                    f"â€¢ Content behind paywall/login\n"
                    f"â€¢ Non-text content (images, videos)\n"
                    f"â€¢ Temporary server issues\n"
                    f"â€¢ Invalid or inaccessible URL\n\n"
                    f"ğŸ’¡ **Suggestions:**\n"
                    f"â€¢ Try a different URL\n"
                    f"â€¢ Check if content is publicly accessible\n"
                    f"â€¢ Ensure URL points to text-based content\n\n"
                    f"ğŸ†” Error ID: `{correlation_id}`",
                )
            elif error_type == "processing_failed":
                detail_block = f"\nğŸ” Reason: {details}" if details else ""
                if self._safe_reply_func is not None:
                    await self._safe_reply_func(
                        message,
                        f"Invalid summary format. Error ID: {correlation_id}{detail_block}",
                    )
                else:
                    message_parts = [
                        "âŒ **Processing Failed**",
                        f"ğŸš¨ Invalid summary format despite smart fallbacks{detail_block}",
                        "",
                        "ğŸ’¡ **What happened:**",
                        "â€¢ The AI models returned data that couldn't be processed",
                        "â€¢ All automatic repair attempts were unsuccessful",
                        "",
                        "ğŸ’¡ **Try:**",
                        "â€¢ Submit the URL again",
                        "â€¢ Try a different article from the same source",
                        "",
                        f"ğŸ†” Error ID: `{correlation_id}`",
                    ]
                    await self._response_sender.safe_reply(message, "\n".join(message_parts))
            elif error_type == "llm_error":
                # Parse details to extract models tried if present
                models_info = ""
                error_info = details or ""

                if "Tried" in error_info and "model(s):" in error_info:
                    # Extract models and error details
                    lines = error_info.split("\n")
                    models_info = lines[0] if lines else ""
                    error_detail = "\n".join(lines[1:]) if len(lines) > 1 else ""
                else:
                    error_detail = f"\nğŸ” Provider response: {details}" if details else ""

                message_parts = [
                    "âŒ **Processing Failed**",
                    "ğŸš¨ All AI models failed despite automatic fallbacks",
                ]

                if models_info:
                    message_parts.append(f"ğŸ“Š {models_info}")

                if error_detail:
                    message_parts.append(error_detail)

                message_parts.extend(
                    [
                        "",
                        "ğŸ’¡ **Possible Solutions:**",
                        "â€¢ Check your account balance/credits",
                        "â€¢ Try again in a few moments",
                        "â€¢ Contact support if the issue persists",
                        "",
                        f"ğŸ†” Error ID: `{correlation_id}`",
                    ]
                )

                await self._response_sender.safe_reply(message, "\n".join(message_parts))
            else:
                # Generic error
                await self._response_sender.safe_reply(
                    message,
                    f"âŒ **Error Occurred**\n"
                    f"ğŸš¨ {details or 'Unknown error'}\n"
                    f"ğŸ†” Error ID: `{correlation_id}`",
                )
        except Exception:
            pass
