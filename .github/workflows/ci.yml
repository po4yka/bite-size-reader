name: CI

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

concurrency:
  group: ci-${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

defaults:
  run:
    shell: bash

permissions:
  contents: read
  packages: write
  pull-requests: write
  checks: write

env:
  UV_EXTRA_INDEX_URL: "https://download.pytorch.org/whl/cpu"
  UV_INDEX_STRATEGY: "unsafe-best-match"

jobs:
  prepare-environment:
    name: Prepare dependencies
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      lock_drift: ${{ steps.lockcheck.outputs.drift }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.13"

      - name: Install uv (fast Python package manager)
        uses: astral-sh/setup-uv@v7
        with:
          version: "0.8.17"
          enable-cache: true
          cache-dependency-glob: |
            pyproject.toml
            uv.lock

      - name: Compile locked requirements (runtime - core only)
        run: uv pip compile pyproject.toml -o requirements.txt

      - name: Compile locked requirements (all extras for tests)
        run: |
          # Include all extras for comprehensive test coverage
          # Scheduler import is now lazy in TelegramBot, avoiding metaclass conflicts
          uv pip compile \
            --extra api \
            --extra ml \
            --extra youtube \
            --extra export \
            --extra scheduler \
            --extra mcp \
            pyproject.toml \
            -o requirements-all.txt

      - name: Compile locked requirements (dev)
        run: uv pip compile --extra dev -c requirements-all.txt pyproject.toml -o requirements-dev.txt

      - name: Check lockfile drift
        id: lockcheck
        run: |
          if git diff --quiet requirements.txt requirements-dev.txt; then
            echo "drift=false" >> "$GITHUB_OUTPUT"
            echo "No lockfile drift detected."
          else
            echo "drift=true" >> "$GITHUB_OUTPUT"
            echo "::warning::Lockfiles are out of date. Run 'make lock-uv' locally or trigger 'Update Lockfiles' workflow."
          fi

      - name: Upload compiled requirements
        uses: actions/upload-artifact@v4
        with:
          name: compiled-requirements
          path: |
            requirements.txt
            requirements-all.txt
            requirements-dev.txt
          retention-days: 1

  markdown-lint:
    name: Lint Markdown
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Lint Markdown files
        uses: DavidAnson/markdownlint-cli2-action@v19
        with:
          globs: |
            **/*.md
            #node_modules
            #.venv

  link-check:
    name: Check Markdown Links
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check links in Markdown files
        uses: lycheeverse/lychee-action@v2
        with:
          args: |
            --verbose
            --no-progress
            --accept 200,204,301,302,429
            --timeout 10
            --max-retries 3
            --exclude 'localhost|127\.0\.0\.1|example\.com|https://github\.com/.*/pull/|https://github\.com/.*/issues/'
            --exclude-path .venv
            --exclude-path node_modules
            '**/*.md'
          fail: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  lint-and-format:
    name: Lint and Format Checks
    needs: prepare-environment
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download compiled requirements
        uses: actions/download-artifact@v4
        with:
          name: compiled-requirements
          path: .

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.13"

      - name: Cache Python environment
        id: cache-python-env
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            ~/.cache/pip
          key: python-lint-${{ runner.os }}-${{ hashFiles('requirements-all.txt', 'requirements-dev.txt') }}
          restore-keys: |
            python-lint-${{ runner.os }}-

      - name: Install uv (fast Python package manager)
        uses: astral-sh/setup-uv@v7
        with:
          version: "0.8.17"
          enable-cache: true
          cache-dependency-glob: |
            pyproject.toml
            uv.lock

      - name: Install dependencies
        run: uv pip sync --system requirements-all.txt requirements-dev.txt

      - name: Validate OpenAPI spec
        run: |
          uv pip install --system openapi-spec-validator
          openapi-spec-validator docs/openapi/mobile_api.yaml
          openapi-spec-validator docs/openapi/mobile_api.json

      - name: Check OpenAPI spec sync with code
        run: pytest tests/api/test_openapi_sync.py -v --tb=short

      - name: Lint (ruff) - comprehensive
        run: ruff check .

      - name: Format check (ruff)
        run: ruff format --check .

      - name: Import sort check (isort)
        run: isort --check-only .

      - name: Enforce class size limit
        run: python scripts/check_class_size.py --max-loc 1000 --baseline scripts/class_size_baseline.json

      - name: Check code complexity
        run: |
          echo "Checking code complexity with radon..."
          uv pip install --system radon
          radon cc app --min B --show-complexity --no-assert
          radon mi app --min B

  type-check:
    name: Type Check (mypy)
    needs: prepare-environment
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download compiled requirements
        uses: actions/download-artifact@v4
        with:
          name: compiled-requirements
          path: .

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.13"

      - name: Cache Python environment
        id: cache-python-env
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            ~/.cache/pip
          key: python-type-${{ runner.os }}-${{ hashFiles('requirements-all.txt', 'requirements-dev.txt') }}
          restore-keys: |
            python-type-${{ runner.os }}-

      - name: Cache mypy
        uses: actions/cache@v4
        with:
          path: .mypy_cache
          key: mypy-${{ runner.os }}-${{ hashFiles('**/*.py', 'pyproject.toml') }}
          restore-keys: |
            mypy-${{ runner.os }}-

      - name: Install uv (fast Python package manager)
        uses: astral-sh/setup-uv@v7
        with:
          version: "0.8.17"
          enable-cache: true
          cache-dependency-glob: |
            pyproject.toml
            uv.lock

      - name: Install dependencies
        run: uv pip sync --system requirements-all.txt requirements-dev.txt

      - name: Type check (mypy)
        run: mypy app tests --show-error-codes --pretty --cache-dir .mypy_cache

  test:
    name: Unit Tests and Coverage
    needs: prepare-environment
    runs-on: ubuntu-latest
    timeout-minutes: 20
    strategy:
      matrix:
        python-version: ["3.13"]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download compiled requirements
        uses: actions/download-artifact@v4
        with:
          name: compiled-requirements
          path: .

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache Python environment
        id: cache-python-env
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            ~/.cache/pip
          key: python-test-${{ runner.os }}-${{ hashFiles('requirements-all.txt', 'requirements-dev.txt') }}
          restore-keys: |
            python-test-${{ runner.os }}-

      - name: Install uv (fast Python package manager)
        uses: astral-sh/setup-uv@v7
        with:
          version: "0.8.17"
          enable-cache: true
          cache-dependency-glob: |
            pyproject.toml
            uv.lock

      - name: Install dependencies (all extras for comprehensive testing)
        run: uv pip sync --system requirements-all.txt requirements-dev.txt

      - name: Install additional test/coverage tools
        run: uv pip install --system pytest-cov pytest-xdist pytest-rerunfailures pytest-asyncio coverage[toml]

      - name: Run unit tests with coverage
        env:
          PYTEST_DISABLE_PLUGIN_AUTOLOAD: "1"
        run: |
          pytest \
            -p pytest_cov \
            -p xdist \
            -p pytest_rerunfailures \
            -p pytest_asyncio.plugin \
            tests/ \
            -m "not slow and not integration" \
            --ignore=tests/benchmarks \
            --ignore=tests/api/test_background_processor.py \
            --ignore=tests/test_api_rate_limit_and_sync.py \
            --cov=app \
            --cov-report=term-missing:skip-covered \
            --cov-report=xml \
            --cov-report=html \
            --cov-config=pyproject.toml \
            --junit-xml=junit-${{ matrix.python-version }}.xml \
            --verbose \
            --maxfail=10 \
            --tb=short \
            --strict-markers \
            --reruns=3 \
            --reruns-delay=1 \
            -n auto

          # Run benchmarks separately without parallel execution
          pytest \
            tests/benchmarks/ \
            -p pytest_benchmark.plugin \
            --verbose \
            --tb=short \
            --benchmark-only \
            --benchmark-disable-gc \
            --benchmark-warmup=on

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.python-version }}
          path: |
            junit-*.xml
            htmlcov/
            coverage.xml
          retention-days: 7

      - name: Test Summary
        if: always()
        uses: test-summary/action@v2
        with:
          paths: "junit-*.xml"

      - name: Upload coverage reports
        uses: codecov/codecov-action@v5
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Check coverage threshold
        run: |
          INCLUDE_PATHS=$(grep -v '^#' scripts/coverage_includes.txt | grep -v '^$' | paste -sd, -)
          coverage report --include="$INCLUDE_PATHS" --fail-under=80 --show-missing

      - name: Surface lockfile drift status
        if: ${{ needs.prepare-environment.outputs.lock_drift == 'true' }}
        run: echo "::warning::Lockfiles are out of date. Run 'make lock-uv' locally or trigger 'Update Lockfiles' workflow."

  docker-image-bot:
    name: Docker Image (Bot)
    needs: prepare-environment
    runs-on: ubuntu-latest
    timeout-minutes: 45
    # Skip Docker build for PRs unless Dockerfile or dependencies changed
    if: |
      github.ref == 'refs/heads/main' ||
      contains(github.event.head_commit.message, '[docker]') ||
      contains(join(github.event.commits.*.modified, ','), 'Dockerfile') ||
      contains(join(github.event.commits.*.modified, ','), 'pyproject.toml') ||
      contains(join(github.event.commits.*.modified, ','), 'uv.lock')
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GHCR
        if: ${{ github.event_name != 'pull_request' && vars.PUBLISH_DOCKER == 'true' }}
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate image tags
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: |
            ghcr.io/${{ github.repository }}
          tags: |
            type=raw,value=latest,enable=${{ github.ref == 'refs/heads/main' }}
            type=sha,format=long

      - name: Build (and optionally push) Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          push: ${{ github.event_name != 'pull_request' && vars.PUBLISH_DOCKER == 'true' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          # Temporarily disable cache to debug build failure
          # cache-from: |
          #   type=gha,scope=bot-builder
          #   type=gha,scope=bot-runtime
          # cache-to: type=gha,mode=max,scope=bot-builder

  docker-image-api:
    name: Docker Image (API)
    needs: prepare-environment
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Skip Docker build for PRs unless Dockerfile.api or dependencies changed
    if: |
      github.ref == 'refs/heads/main' ||
      contains(github.event.head_commit.message, '[docker]') ||
      contains(join(github.event.commits.*.modified, ','), 'Dockerfile.api') ||
      contains(join(github.event.commits.*.modified, ','), 'pyproject.toml') ||
      contains(join(github.event.commits.*.modified, ','), 'uv.lock')
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GHCR
        if: ${{ github.event_name != 'pull_request' && vars.PUBLISH_DOCKER == 'true' }}
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate image tags
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: |
            ghcr.io/${{ github.repository }}-api
          tags: |
            type=raw,value=latest,enable=${{ github.ref == 'refs/heads/main' }}
            type=sha,format=long

      - name: Build (and optionally push) API Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile.api
          push: ${{ github.event_name != 'pull_request' && vars.PUBLISH_DOCKER == 'true' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: |
            type=gha,scope=api-builder
            type=gha,scope=api-runtime
          cache-to: type=gha,mode=max,scope=api-builder

  bandit-scan:
    name: Security - Bandit (SAST)
    needs: prepare-environment
    runs-on: ubuntu-latest
    timeout-minutes: 5
    permissions:
      contents: read
      security-events: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.13'

      - name: Cache Python environment
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            ~/.cache/pip
          key: python-bandit-${{ runner.os }}
          restore-keys: |
            python-bandit-${{ runner.os }}-

      - name: Install bandit
        run: pip install --no-cache-dir bandit

      - name: Run Bandit (SAST)
        run: bandit -r app -ll

  pip-audit-scan:
    name: Security - pip-audit (Dependencies)
    needs: prepare-environment
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: read
      security-events: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download compiled requirements
        uses: actions/download-artifact@v4
        with:
          name: compiled-requirements
          path: .

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.13'

      - name: Cache Python environment
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            ~/.cache/pip
          key: python-pip-audit-${{ runner.os }}
          restore-keys: |
            python-pip-audit-${{ runner.os }}-

      - name: Install pip-audit
        run: pip install --no-cache-dir pip-audit

      - name: Prepare audit requirements
        run: |
          # Filter out spaCy language models that aren't available on PyPI
          cat requirements-all.txt requirements-dev.txt | \
            grep -v "en-core-web-sm" | \
            grep -v "ru-core-news-sm" | \
            # Torch does not yet publish Python 3.13 wheels to PyPI; skip it for auditing
            grep -v "^torch==" | \
            sort -u > requirements-audit.txt

          # Add base spaCy and textacy packages for auditing
          echo "spacy>=3.7,<4" >> requirements-audit.txt
          echo "textacy>=0.13,<0.14" >> requirements-audit.txt

      - name: Run pip-audit
        run: pip-audit -r requirements-audit.txt --strict

  safety-scan:
    name: Security - Safety (Dependencies)
    needs: prepare-environment
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: read
      security-events: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download compiled requirements
        uses: actions/download-artifact@v4
        with:
          name: compiled-requirements
          path: .

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.13'

      - name: Install uv (fast Python package manager)
        uses: astral-sh/setup-uv@v7
        with:
          version: "0.8.17"
          enable-cache: true
          cache-dependency-glob: |
            pyproject.toml
            uv.lock

      - name: Cache Python environment
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            ~/.cache/pip
          key: python-safety-${{ runner.os }}-${{ hashFiles('requirements-all.txt', 'requirements-dev.txt') }}
          restore-keys: |
            python-safety-${{ runner.os }}-

      - name: Install dependencies and safety (all extras for comprehensive scanning)
        run: |
          uv pip sync --system requirements-all.txt requirements-dev.txt
          uv pip install --system safety

      - name: Run Safety
        run: safety check --full-report

  secrets:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: read
      security-events: write
    steps:
      - name: Checkout (full history)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Gitleaks (workspace)
        if: ${{ github.event_name == 'pull_request' }}
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          args: >-
            detect --config .gitleaks.toml --source . --no-git --redact --verbose
            --report-format sarif --report-path ./results-workspace.sarif

      - name: Ensure Gitleaks SARIF exists (workspace)
        if: ${{ github.event_name == 'pull_request' && (success() || failure()) }}
        run: |
          if [ ! -f ./results-workspace.sarif ]; then
            python -c 'from pathlib import Path; import json; payload = {"version": "2.1.0","runs": [{"tool": {"driver": {"name": "gitleaks","informationUri": "https://github.com/gitleaks/gitleaks","rules": []}}, "results": []}]}; Path("results-workspace.sarif").write_text(json.dumps(payload, indent=2))'
            echo "Created empty SARIF report for workspace scan."
          fi

      - name: Upload Gitleaks SARIF (workspace)
        if: ${{ github.event_name == 'pull_request' && (success() || failure()) }}
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: results-workspace.sarif
          category: gitleaks-workspace

      - name: Gitleaks (history)
        if: ${{ github.event_name != 'pull_request' }}
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          args: detect --config .gitleaks.toml --redact --verbose --report-format sarif --report-path results-history.sarif

      - name: Ensure Gitleaks SARIF exists (history)
        if: ${{ github.event_name != 'pull_request' && (success() || failure()) }}
        run: |
          if [ ! -f ./results-history.sarif ]; then
            python -c 'from pathlib import Path; import json; payload = {"version": "2.1.0","runs": [{"tool": {"driver": {"name": "gitleaks","informationUri": "https://github.com/gitleaks/gitleaks","rules": []}}, "results": []}]}; Path("results-history.sarif").write_text(json.dumps(payload, indent=2))'
            echo "Created empty SARIF report for history scan."
          fi

      - name: Upload Gitleaks SARIF (history)
        if: ${{ github.event_name != 'pull_request' && (success() || failure()) }}
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: results-history.sarif
          category: gitleaks-history

  integration-tests:
    name: Integration Tests
    needs: [prepare-environment, test]
    runs-on: ubuntu-latest
    timeout-minutes: 25
    if: github.event_name == 'push' || github.event.pull_request.draft == false
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download compiled requirements
        uses: actions/download-artifact@v4
        with:
          name: compiled-requirements
          path: .

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: "3.13"

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: "0.8.17"
          enable-cache: true

      - name: Install dependencies (all extras for integration tests)
        run: uv pip sync --system requirements-all.txt requirements-dev.txt

      - name: Install test tools
        run: uv pip install --system pytest pytest-timeout pytest-xdist pytest-rerunfailures pytest-asyncio

      - name: Run integration tests
        id: integration_tests
        run: |
          echo "::group::Running integration tests"
          pytest \
            tests/ \
            -m "integration" \
            --ignore=tests/benchmarks \
            --ignore=tests/api/test_background_processor.py \
            --ignore=tests/test_api_rate_limit_and_sync.py \
            --verbose \
            --maxfail=5 \
            --tb=short \
            --strict-markers \
            --timeout=60 \
            --reruns=2 \
            --reruns-delay=2 || EXIT_CODE=$?

          # Exit code 5 means no tests collected (no integration tests marked)
          # This is acceptable - treat as success
          if [ "${EXIT_CODE:-0}" -eq 5 ]; then
            echo "::notice::No integration tests found (all tests deselected)"
            exit 0
          elif [ "${EXIT_CODE:-0}" -ne 0 ]; then
            echo "::error::Integration tests failed with exit code ${EXIT_CODE}"
            exit ${EXIT_CODE}
          fi
          echo "::endgroup::"

      - name: Report integration test status
        if: ${{ failure() && steps.integration_tests.outcome == 'failure' }}
        run: echo "::warning::Integration tests failed - review logs above"

  pr-summary:
    name: PR Summary
    if: github.event_name == 'pull_request'
    needs: [prepare-environment, lint-and-format, type-check, test, bandit-scan, pip-audit-scan, safety-scan, secrets]
    runs-on: ubuntu-latest
    timeout-minutes: 5
    permissions:
      pull-requests: write
    steps:
      - name: Create PR Comment
        uses: actions/github-script@v8
        with:
          script: |
            let summary = '## ✅ CI Summary\n\n';
            const lockDrift = '${{ needs.prepare-environment.outputs.lock_drift }}';
            if (lockDrift === 'true') {
              summary += '⚠️ **Lockfiles are out of date** - Run `make lock-uv` locally\n\n';
            } else {
              summary += '✅ Lockfiles are up to date\n\n';
            }
            summary += '### Checks Completed\n';
            summary += '- ✅ Code linting and formatting\n';
            summary += '- ✅ Type checking (mypy)\n';
            summary += '- ✅ Unit tests with coverage\n';
            summary += '- ✅ Security scanning\n';
            summary += '- ✅ Secret scanning\n\n';
            summary += '_See [full workflow run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) for detailed results._';

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(comment =>
              comment.user.type === 'Bot' && comment.body.includes('CI Summary')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: summary
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: summary
              });
            }

  status-check:
    name: CI Status Check
    if: always()
    needs: [prepare-environment, lint-and-format, type-check, test, docker-image-bot, docker-image-api, bandit-scan, pip-audit-scan, safety-scan, secrets, integration-tests]
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Check all job results
        run: |
          echo "Checking CI status..."

          # Check critical jobs
          if [[ "${{ needs.prepare-environment.result }}" != "success" ]]; then
            echo "::error::prepare-environment job failed"
            exit 1
          fi

          if [[ "${{ needs.lint-and-format.result }}" != "success" ]]; then
            echo "::error::lint-and-format job failed"
            exit 1
          fi

          if [[ "${{ needs.type-check.result }}" != "success" ]]; then
            echo "::error::type-check job failed"
            exit 1
          fi

          if [[ "${{ needs.test.result }}" != "success" ]]; then
            echo "::error::test job failed"
            exit 1
          fi

          # Security scans (parallel)
          if [[ "${{ needs.bandit-scan.result }}" != "success" ]]; then
            echo "::error::bandit-scan job failed"
            exit 1
          fi

          if [[ "${{ needs.pip-audit-scan.result }}" != "success" ]]; then
            echo "::error::pip-audit-scan job failed"
            exit 1
          fi

          if [[ "${{ needs.safety-scan.result }}" != "success" ]]; then
            echo "::error::safety-scan job failed"
            exit 1
          fi

          if [[ "${{ needs.secrets.result }}" != "success" ]]; then
            echo "::error::secrets job failed"
            exit 1
          fi

          # Docker builds can be skipped for PRs, but must succeed if run
          if [[ "${{ needs.docker-image-bot.result }}" == "failure" ]]; then
            echo "::error::docker-image-bot job failed"
            exit 1
          fi

          if [[ "${{ needs.docker-image-api.result }}" == "failure" ]]; then
            echo "::error::docker-image-api job failed"
            exit 1
          fi

          # Integration tests may be skipped when not required
          if [[ "${{ needs.integration-tests.result }}" == "failure" ]]; then
            echo "::error::integration-tests job failed"
            exit 1
          fi

          echo "✅ All critical CI checks passed!"
